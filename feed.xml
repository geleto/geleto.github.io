<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Angel Popov&#39;s Blog</title>
  <subtitle></subtitle>
  <link href="https://geleto.github.io/feed.xml" rel="self"/>
  <link href="https://geleto.github.io/"/>
  
    <updated>2025-10-30T00:00:00Z</updated>
  
  <id>https://geleto.github.io</id>
  <author>
    <name>Angel Popov</name>
    <email>geleto@gmail.com</email>
  </author>
  
    
    <entry>
      <title>The Kitchen Chef&#39;s Guide to Concurrent Programming with Cascada</title>
      <link href="https://geleto.github.io/posts/cascada-kitchen-chef/"/>
      <updated>2025-10-19T00:00:00Z</updated>
      <id>https://geleto.github.io/posts/cascada-kitchen-chef/</id>
      <content type="html">
        <![CDATA[
      <p>Imagine a restaurant kitchen during dinner rush. Two cooks both preheat the oven - one to 200°C for chicken, another to 250°C for pizza. The last one to touch the dial wins, and someone's food is ruined. That's what programmers call a <strong>race condition</strong>.</p>
<p>The fries come out perfectly crispy, but sit waiting for the burger, turning soggy. That's a <strong>dependency problem</strong> - things finishing out of order.</p>
<p>The chef waits for the risotto before plating anything else, even though three other dishes are ready. That's <strong>unnecessary blocking</strong>.</p>
<p>This timing chaos is exactly what makes concurrent programming hard. <a href="https://github.com/geleto/cascada/blob/master/docs/cascada/script.md">Cascada Script</a> - a new scripting language with JavaScript/TypeScript integration that I've been working on - solves this by inverting the traditional model: it's <strong>parallel by default and in-order by exception</strong>. You write simple, in-order, sequential logic, and it automatically runs independent tasks in parallel while guaranteeing every step happens exactly when its data is ready - unless you explicitly want certain steps to happen one after another.</p>
<p>So let's step into a kitchen during dinner rush and see how this works...</p>
<hr>
<h2>The Problem: The Overwhelmed Chef</h2>
<img src="/images/posts/chef.png" alt="Overwhelmed chef in a busy kitchen" style="float: left; margin-right: 20px; margin-bottom: 10px; max-width: 200px; border-radius: 8px;">
<p>First, imagine a kitchen with a talented Head Chef working alone. He's skilled, but it's painfully slow - he can only do one thing at a time.</p>
<p>So he hires a team. Great! Except now he's a frantic micromanager, constantly checking:
“Is the stock reduced yet? Are those shallots ready? Can I start the sauce now?”</p>
<p>This exhausting coordination is what programmers face with asynchronous code - powerful, but easy to get wrong. Cascada eliminates this chaos by automatically tracking dependencies, so you can write logic naturally while it ensures every step happens exactly when it should.</p>
<hr>
<h2>Why This Problem Gets Worse</h2>
<p>Here's the real challenge: Modern kitchens (and modern applications) aren't preparing single meals - they're handling <strong>dozens of simultaneous orders</strong>. Some customers want their dishes modified. The menu changes seasonally. And here's the kicker: <strong>the ingredients don't all arrive at the same time</strong>.</p>
<p>You're receiving shipments, checking multiple suppliers, and waiting on prep stations - all while trying to get food out fast. The traditional approach forces you to manually coordinate every single dependency: &quot;Wait for the truffle delivery, THEN start the risotto. Wait for the beef to sear, THEN make the pan sauce. But don't wait on the salad - that can happen anytime!&quot;</p>
<p>It's a mental nightmare. What you really need is a system that can handle massive parallelism while automatically understanding what must wait for what.</p>
<hr>
<h2>The Naive Fix: Hire More Cooks</h2>
<p>So the Chef tries the obvious solution: hire more cooks and divide the work.</p>
<p>An order arrives for a full six-course banquet for twelve guests. The chef assigns each course to a different cook: &quot;Everyone start now - we need this done in parallel!&quot;</p>
<p>All five cooks rush to begin simultaneously. It should be beautifully parallel.</p>
<p>Except:</p>
<p>The truffle oil hasn't arrived yet, but Cook A is already frantically searching for it to start the risotto. Cook B fires up twelve steaks at once - three medium-rare, six medium, three well-done. The first few finish perfectly seared, then sit... cooling on the counter, losing their heat and their magic... while he waits for the last well-done steaks to catch up. And because everyone started at the exact same moment, all five cooks need the oven at precisely 6:15pm.</p>
<p>They stand there, waiting their turn. The oven becomes a bottleneck.</p>
<p>Meanwhile, the salad cook finishes in 8 minutes but sits idle for the next 30 while waiting for the entrées. The dessert cook started making soufflés immediately... which collapse by the time the main course is finally ready.</p>
<p>The problem? <strong>Starting everything at once</strong> seems parallel, but it ignores reality: ingredients arrive at different times, customers have different preferences, and shared resources create chaos when everyone hits them simultaneously.</p>
<p>What the kitchen needs isn't just dividing work among cooks - it needs <strong>intelligent orchestration</strong> that starts each task exactly when its ingredients are ready, adapts to each order's requirements, and naturally spreads work across resources.</p>
<hr>
<h2>The Solution: The Cascada Kitchen Manager</h2>
<img src="/images/posts/robot.png" alt="Hard-working robot manager in a busy kitchen" style="float: left; margin-right: 20px; margin-bottom: 10px; max-width: 200px; border-radius: 8px;">
<p>Now, imagine a completely different kitchen. Here, the Head Chef's job is not to manage, but to <strong>design</strong>.</p>
<p>He sits down in a quiet office and writes out the entire, complex banquet recipe. And here is the most crucial part: <strong>he writes it just as he always has, in a simple, sequential, top-to-bottom list of steps. It looks and feels like any other recipe he's ever written.</strong></p>
<p>But this simple-looking recipe is incredibly powerful because <strong>it's a smart, adaptable plan</strong>. The Chef can include rules, choices, and logic as part of his normal, sequential writing:</p>
<ul>
<li>&quot;<strong>If</strong> the season is Winter, use the root vegetables. <strong>Otherwise</strong>, use the summer squash.&quot;</li>
<li>&quot;<strong>For each</strong> of the 12 dinner orders for the main party, prepare one beef medallion to the customer's requested temperature.&quot;</li>
</ul>
<p>The recipe isn't a rigid checklist - it's a flexible blueprint that responds to real-world conditions.</p>
<p>Once this smart, yet familiar-looking recipe is written, his main job is done. He hands it to a brilliant <strong>Kitchen Manager</strong> (that's <a href="https://github.com/geleto/cascada/blob/master/docs/cascada/script.md">Cascada</a>) and can go relax.</p>
<p>The Manager doesn't just read a fixed list. He <strong>interprets this smart recipe in real-time, as things are happening.</strong> He checks the calendar, sees the 12 orders, understands the client's needs, and then executes the Chef's simple, sequential logic with maximum parallelism, handling all the complexity himself.</p>
<hr>
<h2>Understanding Ingredient Dependencies</h2>
<img src="/images/posts/dependencies.png" alt="Ingredient dependencies chart" style="float: left; margin-right: 20px; margin-bottom: 10px; max-width: 200px; border-radius: 8px;">
<p>The Kitchen Manager is smart enough to handle dependencies within this dynamic logic automatically. Imagine the recipe calls for a final pan sauce, which requires three things: the pan the beef was seared in, some sautéed shallots, and the reduced red wine.</p>
<p>He orchestrates a multi-part ballet:</p>
<ul>
<li>He has Assistant D searing the beef.</li>
<li>Simultaneously, he has Assistant E sautéing shallots.</li>
<li>And at the same time, Assistant F is reducing the wine.</li>
<li>He then tells a final assistant, Assistant G: &quot;Stand by. You cannot start your job until the beef is done, the shallots are ready, AND the wine is reduced. The moment all three are finished - no matter the timing - you will combine them to create the final sauce.&quot;</li>
</ul>
<p>While Assistant G is waiting for these multiple inputs, the rest of the kitchen is not waiting with him! Other dishes are being prepped, other sauces are being reduced. This automatic waiting - without blocking anything else - is the fundamental principle that makes the system so efficient.</p>
<p>The Chef never wrote &quot;wait for the beef&quot; or &quot;check if the shallots are ready.&quot; He just wrote the recipe in order. The Manager figured out the dependencies automatically.</p>
<hr>
<h2>When Order is Everything: The Critical Path (!)</h2>
<p>Even within this smart, parallel kitchen, some actions on a <em>single item</em> must happen in a strict sequence. You can't deglaze a pan before you've sautéed the shallots in it.</p>
<p>Right in the middle of the recipe, the Chef can mark specific items with a ! symbol to create what's called a <strong>critical path</strong>.</p>
<p>For example, scattered throughout the recipe you might see:</p>
<ul>
<li><code>Saucepan! Sauté the shallots until translucent.</code></li>
<li>(Many other parallel instructions for different dishes...)</li>
<li><code>Saucepan! Deglaze the pan with brandy.</code></li>
<li>(More parallel work...)</li>
<li><code>Saucepan! Add the stock and reduce by half</code>.</li>
</ul>
<p>When the Kitchen Manager encounters the ! on the <strong>Saucepan</strong>, he assigns one dedicated assistant to follow <em>only</em> the saucepan's instructions, in the exact order they appear. This creates a &quot;single-file line&quot; for that saucepan only, while all other assistants continue their parallel work on steaks, salads, and desserts.</p>
<p>The ! doesn't slow down the kitchen - it just ensures that when order matters for a specific item, that order is guaranteed.</p>
<hr>
<h2>The Final Pass: Plating Station (@)</h2>
<p>Here's a challenge: In our chaotic parallel kitchen, dishes finish in unpredictable order. The beef for Table 5 might be done before Table 3's. The garnish might arrive before the protein. How do you ensure every plate that leaves the kitchen is perfect and consistently presented?</p>
<p>The Chef solves this with the @ symbol, which marks items for the <strong>final pass plating station</strong> - a dedicated area where one master plater assembles each dish only after ALL its components are ready.</p>
<p>Throughout the recipe's logic, you might see lines like this:</p>
<ul>
<li>Beef Medallion @ Place in the center of the plate.</li>
<li>(Logic to determine which vegetable to cook based on season...)</li>
<li>Vegetable @ Arrange artfully next to the medallion.</li>
<li>(More parallel cooking of sauces, sides...)</li>
<li>Pan Sauce @ Drizzle over the medallion.</li>
</ul>
<p>As the Manager interprets the recipe's dynamic logic - perhaps preparing 12 plates because there are 12 guests - he collects every @ instruction he encounters and puts it on a special clipboard.</p>
<p><strong>Only after every single cooking and preparation step in the entire recipe is complete</strong> does the Manager pick up that clipboard and hand it to the final plating station. The plater then reads the @ instructions one-by-one, in the exact order they were collected, and assembles each perfect plate.</p>
<p>This ensures that even though the kitchen is running 50 orders simultaneously with components finishing in chaotic order, every dish that goes out is assembled with perfect consistency and care.</p>
<hr>
<h2>The Domino Effect: Handling Kitchen Disasters</h2>
<p>A perfect recipe assumes a perfect kitchen, but in reality, things go wrong. An oven breaks. A key ingredient is missing. An assistant calls in sick.</p>
<p>Traditional kitchens panic - the whole operation can grind to a halt. But the <a href="https://github.com/geleto/cascada/blob/master/docs/cascada/script.md">Cascada</a> Manager handles disasters with what's called <strong><code>error propagation</code></strong> - a controlled ripple effect that contains problems without stopping the entire kitchen.</p>
<p>Imagine someone discovers the truffles that arrived this morning are actually expired and can't be used. The Manager immediately marks <strong>Truffles</strong> as &quot;contaminated&quot; - or in <a href="https://github.com/geleto/cascada/blob/master/docs/cascada/script.md">Cascada</a> terms, &quot;poisoned&quot; (we use this word figuratively to describe how one bad piece of data makes everything depending on it unusable too). This contamination then flows through the dependency chain: the <strong>Truffle Risotto</strong>, which needs those truffles, automatically becomes &quot;unavailable&quot; as well.</p>
<p>Crucially, the assistants making the steak and salad are unaffected. They never needed truffles, so they continue working at full speed. The problem is perfectly contained.</p>
<h3>Three Ways to Handle Disasters</h3>
<p>The Head Chef has powerful options for dealing with unavailable items:</p>
<p><strong>1. Intervene Immediately:</strong> The moment the truffles become unavailable, a contingency plan can trigger automatically: <em>&quot;Send an assistant to the specialty market to buy more!&quot;</em> If they succeed, the problem is solved and the risotto is back on track. This is perfect for retrying failed operations.</p>
<p><strong>2. Substitute Gracefully:</strong> The recipe itself can have a backup plan built in: <em>&quot;If fresh truffles are unavailable, use high-quality mushroom duxelles instead.&quot;</em> The Manager sees this, makes the substitution, and the problem is stopped before it spreads.</p>
<p><strong>3. Check and Adapt Later:</strong> You can also do nothing immediately. The risotto simply remains &quot;unavailable.&quot; Later, you can check its status and decide how to proceed. Maybe you offer the customer an alternative dish. Or perhaps the truffles finally arrive from a backup supplier - in which case you can restart the risotto preparation with the fresh ingredients. The choice of if, when and how to handle the problem is always yours.</p>
<p>The beauty is that unavailability doesn't cause crashes or confusion - it's just information that flows through the system, letting you respond at the right moment.</p>
<hr>
<h2>The Takeaway: Effortless Parallelism</h2>
<p>You write as if every step were a single, simple action. Yet beneath the surface, the system runs a perfectly choreographed symphony of parallel work.</p>
<p>That's the quiet power of being <em>implicitly parallel by design.</em></p>
<h2>Learn More and Try It Yourself</h2>
<p>📖 <strong>Cascada Script Documentation:</strong> <a href="https://github.com/geleto/cascada/blob/master/docs/cascada/script.md">github.com/geleto/cascada/blob/master/docs/cascada/script.md</a></p>
<p>🧩 <strong>Cascada GitHub Repository:</strong> <a href="https://github.com/geleto/cascada">github.com/geleto/cascada</a></p>
<p>🤖 <strong>Cascador-AI:</strong> <a href="https://github.com/geleto/cascador-ai">github.com/geleto/cascador-ai</a> - an AI orchestration library built on Cascada for effortless, parallel agent and workflow design.</p>
<p>⚡ <strong>Try it now:</strong></p>
<pre class="language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> cascada-engine</code></pre>
<hr>

    ]]>
      </content>
    </entry>
  
    
    <entry>
      <title>Cascada Script: Parallel by Default, Sequential by Exception</title>
      <link href="https://geleto.github.io/posts/cascada-script-intro/"/>
      <updated>2025-10-30T00:00:00Z</updated>
      <id>https://geleto.github.io/posts/cascada-script-intro/</id>
      <content type="html">
        <![CDATA[
      <p><strong><a href="https://github.com/geleto/cascada/blob/master/docs/cascada/script.md">Cascada Script</a></strong> is a scripting language with JavaScript and TypeScript integration that turns async programming upside down: everything runs in parallel by default, you never write <code>await</code>, and concurrency issues like race conditions are no longer a problem - by design.</p>
<h3>The Nightmare: Callbacks, Promises, and Death by a Thousand <code>await</code>s</h3>
<p>Let's be honest: <code>async/await</code> is a huge improvement for writing asynchronous code. It lets us write clean, sequential-looking logic. But the moment we want to maximize performance, we're forced into a manual balancing act.</p>
<p>We start juggling: &quot;Should I <code>await</code> this call directly? Or should I group these three tasks into a <code>Promise.all</code> to run them in parallel?&quot;</p>
<p>This is where the trouble begins. <code>Promise.all</code> is powerful, but it's a blunt instrument - <strong>it's the programming equivalent of telling everyone to start at exactly the same time and wait for the slowest person to finish.</strong></p>
<p>This &quot;explicit parallelism&quot; model isn't just a quirk of JavaScript; it's the dominant pattern across the entire industry. And here lies the great missed opportunity: tools like LangChain - from its basic RunnableParallel to the stateful, turn-based model of LangGraph—provide powerful graph abstractions that are perfectly suited for implicit dataflow concurrency, yet they don't leverage it. They still expect you to be the concurrency expert. They hand you the tools and expect you to manually identify and orchestrate what can run together. (I'd genuinely love to be proven wrong on this.)</p>
<p>The problems cascade from there:</p>
<ul>
<li>
<p><strong>You start operations before their inputs are ready.</strong> Fire off a request for post comments before you have the post IDs? Your code crashes or makes wasteful, redundant calls.</p>
</li>
<li>
<p><strong>Fast operations are held hostage by slow ones.</strong> You fetch 20 user profiles in parallel - 19 return in 50ms, but one slow API takes 3 seconds. Everything waits. Your fast results sit idle while the clock ticks.</p>
</li>
<li>
<p><strong>Resource bottlenecks emerge.</strong> All your operations hit the same database connection pool simultaneously. Instead of spreading naturally, they queue up and block each other.</p>
</li>
<li>
<p><strong>Complex dependency graphs become impossible to reason about.</strong> User data feeds into both posts AND preferences (which should run in parallel), which then feed into enriched analytics (which must wait for both). Manually orchestrating this with nested <code>await</code>s and carefully placed <code>Promise.all</code> calls turns your clean business logic into brittle async plumbing that breaks when requirements change.</p>
</li>
</ul>
<p>The payoff for getting this right is enormous - optimal orchestration can often cut response times in half or more. But achieving it manually? That's where the complexity becomes daunting.</p>
<p>What if you could just write your code as a straightforward, top-to-bottom script, and let a smart engine handle all the complex concurrent execution for you? That's exactly what <strong><a href="https://github.com/geleto/cascada/blob/master/docs/cascada/script.md">Cascada Script</a></strong> does.</p>
<h2>Let's dive into how it flips the script on async programming.</h2>
<h2>1. ⚡ Parallel by Default</h2>
<p>The most fundamental shift in Cascada is that it's <strong>parallel by default</strong>. In most languages, code runs line by line, one after the other. In Cascada, any independent lines of code run at the same time.</p>
<p>Think about fetching a user's profile and their recent posts. These are two separate operations that don't depend on each other. In traditional JavaScript, you'd need <code>Promise.all</code> to run them concurrently. Cascada does it automatically.</p>
<pre class="language-javascript"><code class="language-javascript"><span class="token comment">// These three operations start at the same time, automatically!</span>
<span class="token keyword">var</span> user <span class="token operator">=</span> <span class="token function">fetchUser</span><span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>
<span class="token keyword">var</span> preferences <span class="token operator">=</span> <span class="token function">getUserPreferences</span><span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>
<span class="token keyword">var</span> analytics <span class="token operator">=</span> <span class="token function">getAnalytics</span><span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>

<span class="token comment">// Build your result with the @ operator</span>
@data<span class="token punctuation">.</span>user <span class="token operator">=</span> user
@data<span class="token punctuation">.</span>preferences <span class="token operator">=</span> preferences
@data<span class="token punctuation">.</span>analytics <span class="token operator">=</span> analytics
<span class="token comment">// Result: { user: {...}, preferences: {...}, analytics: {...} }</span></code></pre>
<p>No <code>Promise.all</code>, no await, no special syntax. If it <em>can</em> run in parallel, it <em>will</em>.</p>
<hr>
<h2>2. 🚦 Data-Driven Flow: Code Runs When Its Inputs Are Ready</h2>
<p>You might be thinking, &quot;What if one operation <em>does</em> depend on another?&quot; Cascada has you covered.</p>
<p>The engine automatically analyzes the data dependencies in your script. An operation will only run once all the variables it needs are ready. This simple rule guarantees the correct order of execution and <strong>completely eliminates race conditions by design</strong>.</p>
<pre class="language-javascript"><code class="language-javascript"><span class="token comment">// 1. This runs first</span>
<span class="token keyword">var</span> user <span class="token operator">=</span> <span class="token function">fetchUser</span><span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>

<span class="token comment">// 2. This depends on 'user', so Cascada waits for it to resolve</span>
<span class="token keyword">var</span> userGreeting <span class="token operator">=</span> <span class="token string">"Hello, "</span> <span class="token operator">+</span> user<span class="token punctuation">.</span>name

<span class="token comment">// 3. Meanwhile, these run in parallel with everything above</span>
<span class="token keyword">var</span> posts <span class="token operator">=</span> <span class="token function">fetchPosts</span><span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>
<span class="token keyword">var</span> comments <span class="token operator">=</span> <span class="token function">fetchComments</span><span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span></code></pre>
<p>Here, <code>userGreeting</code> won't be calculated until <code>fetchUser(123)</code> is complete and the <code>user</code> variable has a value. But <code>posts</code> and <code>comments</code> start fetching immediately since they don't depend on <code>user</code>.</p>
<p>No more subtle timing bugs that only appear in production. The engine orchestrates everything automatically.</p>
<hr>
<h2>3. ✨ Implicit Concurrency: Write Business Logic, Not Async Plumbing</h2>
<p>This is where the magic really happens. Notice the lack of <code>await</code> in the examples above? In Cascada, you never have to think about whether a variable holds a value or a promise. You just use it.</p>
<pre class="language-javascript"><code class="language-javascript"><span class="token comment">// Traditional JavaScript: Promise hell</span>
<span class="token keyword">const</span> userPromise <span class="token operator">=</span> <span class="token function">fetchUser</span><span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> name <span class="token operator">=</span> <span class="token keyword">await</span> userPromise<span class="token punctuation">.</span>name<span class="token punctuation">;</span> <span class="token comment">// Wait, can't do this!</span>
<span class="token keyword">const</span> actualUser <span class="token operator">=</span> <span class="token keyword">await</span> userPromise<span class="token punctuation">;</span>
<span class="token keyword">const</span> name <span class="token operator">=</span> actualUser<span class="token punctuation">.</span>name<span class="token punctuation">;</span> <span class="token comment">// Finally!</span></code></pre>
<p>Cascada makes this completely invisible:</p>
<pre class="language-javascript"><code class="language-javascript"><span class="token comment">// Cascada: Just use it</span>
<span class="token keyword">var</span> user <span class="token operator">=</span> <span class="token function">fetchUser</span><span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>

<span class="token comment">// The @data command builds our final JSON output</span>
@data<span class="token punctuation">.</span>greet <span class="token operator">=</span> <span class="token string">"Hello, "</span> <span class="token operator">+</span> user<span class="token punctuation">.</span>name
@data<span class="token punctuation">.</span>email <span class="token operator">=</span> user<span class="token punctuation">.</span>email
@data<span class="token punctuation">.</span>status <span class="token operator">=</span> user<span class="token punctuation">.</span>isActive <span class="token operator">?</span> <span class="token string">"active"</span> <span class="token operator">:</span> <span class="token string">"inactive"</span></code></pre>
<p>Forget <code>.then()</code> and forget manually tracking promises. Cascada handles the asynchronous state invisibly under the hood. You can pass a &quot;future value&quot; (a promise) into a function or use it in an expression, and it just works.</p>
<p>This lets you focus entirely on your business logic, not the async plumbing.</p>
<hr>
<h2>4. ➡️ Implicitly Parallel, Explicitly Sequential</h2>
<p>Of course, sometimes you absolutely need things to happen in a specific order, especially when dealing with operations that have side effects - like writing to a database or making stateful API calls.</p>
<p>For these cases, Cascada provides a simple escape hatch: the <code>!</code> marker. Marking a call or path with <code>!</code> enforces a strict sequential order on that specific path, without slowing down the rest of your script. A call does not need a data dependency from another to run in sequence.</p>
<pre class="language-javascript"><code class="language-javascript"><span class="token comment">// The ! marker creates a sequential chain for a specific path</span>
<span class="token keyword">var</span> account <span class="token operator">=</span> <span class="token function">getBankAccount</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">// 1. This MUST finish first</span>
account<span class="token operator">!</span><span class="token punctuation">.</span><span class="token function">deposit</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span>
<span class="token comment">// 2. This waits for deposit to complete</span>
account<span class="token punctuation">.</span><span class="token function">getStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">// 3. This waits for getStatus</span>
account<span class="token operator">!</span><span class="token punctuation">.</span><span class="token function">withdraw</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span>

<span class="token comment">// Meanwhile, these run in parallel with everything above</span>
<span class="token keyword">var</span> preferences <span class="token operator">=</span> <span class="token function">getUserPreferences</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
preferences<span class="token operator">!</span><span class="token punctuation">.</span><span class="token function">update</span><span class="token punctuation">(</span>prefs<span class="token punctuation">)</span>   <span class="token comment">// Sequential chain for preferences too</span>
<span class="token keyword">var</span> analytics <span class="token operator">=</span> <span class="token function">fetchAnalytics</span><span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<p>The <code>!</code> creates a sequential chain for just that specific path, without affecting the parallelism of everything else. It's <strong>parallel by default, sequential by exception</strong> - the opposite of traditional programming.</p>
<hr>
<h2>5. 📋 Chaotic Execution, Predictable Output</h2>
<p>While independent operations run in parallel and can finish in any order, Cascada guarantees that your <strong>final output is assembled predictably</strong>.</p>
<p>Data manipulation commands (like adding an item to a list) are applied in the exact order they appear in your script. So even if a <code>for</code> loop's iterations complete out of order, the final array will be structured correctly.</p>
<pre class="language-javascript"><code class="language-javascript"><span class="token keyword">var</span> userIds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">101</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">,</span> <span class="token number">103</span><span class="token punctuation">]</span>

<span class="token comment">// All three fetchUserDetails calls run in parallel</span>
<span class="token comment">// Maybe user 103's data comes back first</span>
<span class="token keyword">for</span> id <span class="token keyword">in</span> userIds
  <span class="token keyword">var</span> details <span class="token operator">=</span> <span class="token function">fetchUserDetails</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span>
  @data<span class="token punctuation">.</span>users<span class="token punctuation">.</span><span class="token function">push</span><span class="token punctuation">(</span>details<span class="token punctuation">.</span>name<span class="token punctuation">)</span>
endfor

<span class="token comment">// Even so, the final output is ALWAYS predictable and in order:</span>
<span class="token comment">// { "users": ["Alice", "Bob", "Charlie"] }</span></code></pre>
<p>This gives you the best of both worlds: maximum I/O performance from parallel execution, with the reliability of sequential data assembly.</p>
<hr>
<h2>6. ☣️ Dataflow Poisoning: Resilient Error Handling</h2>
<p>Traditional <code>try/catch</code> blocks don't work well in a massively parallel system. If one of fifty concurrent API calls fails, should everything stop?</p>
<p>Cascada uses a more resilient model called <strong>dataflow poisoning</strong>. When an operation fails, it doesn't throw an exception; it produces an <code>Error Value</code>. This error then &quot;poisons&quot; any other variable or operation that depends on it. Crucially, unrelated operations continue running completely unaffected.</p>
<pre class="language-javascript"><code class="language-javascript"><span class="token comment">// Let's pretend fetchPosts() fails, but fetchUser() succeeds</span>
<span class="token keyword">var</span> user <span class="token operator">=</span> <span class="token function">fetchUser</span><span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>            <span class="token comment">// ✅ Succeeds</span>
<span class="token keyword">var</span> posts <span class="token operator">=</span> <span class="token function">fetchPosts</span><span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>          <span class="token comment">// ❌ Fails and becomes an Error Value</span>
<span class="token keyword">var</span> comments <span class="token operator">=</span> <span class="token function">fetchComments</span><span class="token punctuation">(</span>posts<span class="token punctuation">)</span>  <span class="token comment">// ☣️ Poisoned because it uses 'posts'</span>

<span class="token comment">// Now, let's see what happens:</span>
@data<span class="token punctuation">.</span>userName <span class="token operator">=</span> user<span class="token punctuation">.</span>name     <span class="token comment">// ✅ Works fine, uses the successful result</span>
@data<span class="token punctuation">.</span>postCount <span class="token operator">=</span> posts<span class="token punctuation">.</span>length <span class="token comment">// ❌ Becomes an error because 'posts' is poisoned</span>

<span class="token comment">// You can check for errors and provide fallbacks</span>
<span class="token keyword">if</span> posts is error
  posts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment">// Assign a default value</span>
endif

@data<span class="token punctuation">.</span>postCount <span class="token operator">=</span> posts<span class="token punctuation">.</span>length <span class="token comment">// ✅ Now works with our fallback</span></code></pre>
<p>This approach isolates failures, prevents corrupted data from producing incorrect results, and makes your workflows incredibly robust.</p>
<p>The beauty of dataflow poisoning is that you have <strong>complete control over recovery</strong>. You can detect errors at any point in your workflow (using <code>is error</code> conditions), repair them with fallback values, log them for monitoring, or even retry failed operations - all while the rest of your script continues executing normally.</p>
<hr>
<h2>7. 💡 Clean, Expressive Syntax</h2>
<p>Cascada offers a clean, expressive syntax that will feel instantly familiar if you know JavaScript. You can use variables, loops, conditionals, and build reusable macros.</p>
<pre class="language-javascript"><code class="language-javascript"><span class="token comment">// Variables, conditionals, loops</span>
<span class="token keyword">var</span> discount <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>

<span class="token keyword">if</span> userType <span class="token operator">==</span> <span class="token string">"premium"</span>
  <span class="token keyword">var</span> discount <span class="token operator">=</span> <span class="token number">0.10</span>
endif

<span class="token comment">// Build reusable macros</span>
macro <span class="token function">formatPrice</span><span class="token punctuation">(</span>amount<span class="token punctuation">,</span> discount<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
  <span class="token keyword">var</span> final <span class="token operator">=</span> amount <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> discount<span class="token punctuation">)</span>
  @text <span class="token operator">&lt;&lt;</span> <span class="token string">"$"</span> <span class="token operator">+</span> final
endmacro

<span class="token function">formatPrice</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> discount<span class="token punctuation">)</span>  <span class="token comment">// Outputs: $90</span></code></pre>
<p>You get variables (<code>var</code>), conditionals (<code>if/else</code>), loops (<code>for/while</code>), macros for reusability (<code>macro</code>), and modular code organization with <code>import</code> and <code>extends</code>.</p>
<hr>
<h2>8. ⚙️ Under the Hood: Chaos Managed Gracefully</h2>
<p>Underneath all this simplicity is a powerful engine that:</p>
<ul>
<li><strong>Tracks data dependencies automatically</strong> so operations run when their inputs are ready</li>
<li><strong>Handles concurrent execution safely</strong> with maximum I/O throughput</li>
<li><strong>Guarantees consistent, deterministic outputs</strong> even with chaotic parallel execution</li>
<li><strong>Propagates errors without crashing</strong> so failures are isolated and manageable</li>
</ul>
<p>You focus on <em>what</em> you want to happen. The engine handles <em>how</em> to make it happen safely and efficiently.</p>
<hr>
<h2>🎯 Why This Matters</h2>
<p>Cascada isn't trying to replace JavaScript - it's designed to be the backbone of your data layer.</p>
<p>Use it to compose complex workflows that wire together LLMs, APIs, databases, and external services. By inverting the traditional programming model - parallel by default, sequential by exception - it lets you build high-performance data pipelines that are surprisingly simple and intuitive all with maximum I/O throughput and minimum mental overhead.</p>
<p>The result? <strong>Code that reads like synchronous logic but executes with the performance of carefully orchestrated async operations.</strong> You get to focus on <em>what</em> you're building instead of <em>how</em> to manage promises, race conditions, and execution order.</p>
<p>And the best part? When you look at your Cascada script six months later, you'll actually understand what it does.</p>
<hr>
<h2>🚀 Ready to Simplify Your Async Code?</h2>
<p>Cascada is <code>a work in progress</code> under active development and evolving quickly. Install it with:</p>
<pre class="language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> cascada-engine</code></pre>
<p>And start writing async code that makes sense:</p>
<pre class="language-javascript"><code class="language-javascript"><span class="token keyword">import</span> <span class="token punctuation">{</span> AsyncEnvironment <span class="token punctuation">}</span> <span class="token keyword">from</span> <span class="token string">'cascada-engine'</span><span class="token punctuation">;</span>

<span class="token keyword">const</span> env <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AsyncEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> script <span class="token operator">=</span> <span class="token template-string"><span class="token template-punctuation string">`</span><span class="token string">
  var user = fetchUser(123)
  var posts = fetchPosts(user.id)

  @data.welcome = "Hello, " + user.name
  @data.postCount = posts.length
</span><span class="token template-punctuation string">`</span></span><span class="token punctuation">;</span>

<span class="token keyword">const</span> result <span class="token operator">=</span> <span class="token keyword">await</span> env<span class="token punctuation">.</span><span class="token function">renderScriptString</span><span class="token punctuation">(</span>script<span class="token punctuation">,</span> context<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// { welcome: 'Hello, Alice', postCount: 42 }</span></code></pre>
<p><strong>⚠️ Heads up!</strong> Cascada is a new project. You might run into bugs, and the documentation is catching up with the code. Your feedback and contributions are welcome as we build the future of asynchronous programming.</p>
<hr>
<h2>Final Thoughts</h2>
<p>If you've ever fought through promise hell, callback pyramids, or race conditions, Cascada might just feel like magic.</p>
<p>It turns async programming from a juggling act into a walk in the park. You write code like a human - simple, sequential, intuitive - and let the runtime handle the parallelism and safety behind the scenes.</p>
<p>The future of async programming isn't about getting better at promises. It's about not having to think about them at all.</p>

    ]]>
      </content>
    </entry>
  
</feed>